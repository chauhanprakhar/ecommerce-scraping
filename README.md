# Web Scraping Tool

A FastAPI-based web scraping tool designed to efficiently scrape product information from e-commerce websites. The tool features configurable settings, caching mechanisms, and extensible storage options.

## Features

- ğŸš€ Asynchronous web scraping
- ğŸ”’ API key authentication
- ğŸ’¾ Configurable storage strategies
- ğŸ“¦ Redis-based caching system
- ğŸ”„ Automatic retry mechanism
- ğŸŒ Proxy support
- ğŸ“§ Extensible notification system

## Prerequisites

- Python 3.8+
- Redis server
- Virtual environment (recommended)

## Installation

1. Clone the repository
```bash
git clone <repository-url>
cd scraping-tool
```

2. Create and activate virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

## Configuration

Create a `.env` file in the root directory:
```env
AUTH_TOKEN=your-secret-token
REDIS_URL=redis://localhost:6379
DEFAULT_TARGET_URL=https://example-shop.com
RETRY_ATTEMPTS=3
RETRY_DELAY=5
```

## Project Structure
```
app/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schema.py
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ scraper.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ json_storage.py
â”œâ”€â”€ notifications/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ console.py
â””â”€â”€ cache/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ redis_cache.py
```

## Usage

1. Start the application:
```bash
uvicorn app.main:app --reload
```

2. Make a scraping request:
```bash
curl -X POST "http://localhost:8000/scrape/" \
-H "X-API-Key: your-secret-token" \
-H "Content-Type: application/json" \
-d '{
  "page_limit": 5,
  "proxy": "http://proxy.example.com:8080",
  "target_url": "https://example-shop.com"
}'
```

## API Documentation

### POST /scrape/
Scrapes product information from the specified website.

**Request Body:**
```json
{
  "page_limit": 5,          // Optional: Limit number of pages to scrape
  "proxy": "http://...",    // Optional: Proxy server URL
  "target_url": "https://..." // Optional: Target website URL
}
```

**Response:**
```json
[
  {
    "product_title": "Example Product",
    "product_price": 299.99,
    "path_to_image": "images/example-product.jpg"
  }
]
```

## Error Handling

The application includes comprehensive error handling:
- Authentication errors (403)
- Invalid input validation (422)
- Automatic retry for failed requests
- Rate limiting protection


## License

This project is licensed under the MIT License - see the LICENSE file for details.
